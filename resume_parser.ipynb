{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb769a-802e-4976-b747-5d2e0afeca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json, re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import fitz  # PyMuPDF\n",
    "from pdfminer.high_level import extract_text as pdfminer_extract\n",
    "import docx\n",
    "from pydantic import BaseModel, Field, field_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f1091-b664-43f2-b953-d279843e78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Output schema =====\n",
    "class ResumeOut(BaseModel):\n",
    "    name: str = Field(..., description=\"Full candidate name\")\n",
    "    email: str = Field(..., description=\"Primary email address\")\n",
    "    skills: List[str] = Field(default_factory=list, description=\"List of distinct skills\")\n",
    "\n",
    "    @field_validator(\"name\")\n",
    "    @classmethod\n",
    "    def _n(cls, v: str) -> str:\n",
    "        return \" \".join(v.split()).strip().title()\n",
    "\n",
    "    @field_validator(\"email\")\n",
    "    @classmethod\n",
    "    def _e(cls, v: str) -> str:\n",
    "        return v.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a67cb-03ab-49bf-93e2-c79356451e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Text extraction =====\n",
    "def read_text(path: Path) -> str:\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".pdf\":\n",
    "        try:\n",
    "            with fitz.open(path) as doc:\n",
    "                blocks = []\n",
    "                for pg in doc:\n",
    "                    for x0,y0,x1,y1,txt,*_ in pg.get_text(\"blocks\"):\n",
    "                        if txt and txt.strip():\n",
    "                            blocks.append((int(y0), int(x0), txt.strip()))\n",
    "                blocks.sort(key=lambda t: (t[0], t[1]))\n",
    "                text = \"\\n\".join(b[2] for b in blocks)\n",
    "        except Exception:\n",
    "            text = \"\"\n",
    "        if not text.strip() and path.stat().st_size < 5_000_000:\n",
    "            try:\n",
    "                text = pdfminer_extract(str(path)) or \"\"\n",
    "            except Exception:\n",
    "                text = \"\"\n",
    "        return text\n",
    "    elif ext == \".docx\":\n",
    "        d = docx.Document(str(path))\n",
    "        return \"\\n\".join(p.text for p in d.paragraphs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d5192-fd7c-4423-810c-976bd2cd3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Prompting helpers =====\n",
    "MAX_CHARS = 8000\n",
    "def truncate(s: str, max_chars: int = MAX_CHARS) -> str:\n",
    "    s = s.strip()\n",
    "    return s if len(s) <= max_chars else s[:max_chars]\n",
    "    \n",
    "SYSTEM_INSTRUCTIONS = (\n",
    "    \"You extract structured data. \"\n",
    "    \"Return ONLY valid JSON that matches the schema. \"\n",
    "    \"Rules: dedupe skills, use canonical names if obvious, no prose.\"\n",
    ")\n",
    "\n",
    "USER_TEMPLATE = (\n",
    "    \"Extract name, primary email, and skills from this resume text.\\n\\n\"\n",
    "    \"=== RESUME TEXT START ===\\n{chunk}\\n=== RESUME TEXT END ===\"\n",
    ")\n",
    "\n",
    "EMAIL_RX = re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,24}\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564c193-4692-42d9-be59-a7546506ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(d: Dict) -> ResumeOut:\n",
    "    m = EMAIL_RX.search((d.get(\"email\") or \"\")) or EMAIL_RX.search(d.get(\"name\",\"\"))\n",
    "    email = m.group(0).lower() if m else \"\"\n",
    "    seen=set(); skills=[]\n",
    "    for s in d.get(\"skills\") or []:\n",
    "        k=s.strip().lower()\n",
    "        if k and k not in seen: seen.add(k); skills.append(s.strip())\n",
    "    return ResumeOut(name=d.get(\"name\",\"\").strip(), email=email, skills=skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade83a7-6008-4567-bfa0-79f378271955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_or_fill(json_text: str) -> Dict:\n",
    "    try:\n",
    "        d = json.loads(json_text)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}\", json_text, flags=re.S)\n",
    "        d = json.loads(m.group(0)) if m else {}\n",
    "    return {\"name\": d.get(\"name\",\"\"), \"email\": d.get(\"email\",\"\"), \"skills\": d.get(\"skills\", [])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634950e-7251-403c-87a7-3369b87e3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_ollama(host: str | None = None) -> None:\n",
    "    import urllib.request, json, os\n",
    "    host = host or os.getenv(\"OLLAMA_HOST\",\"http://127.0.0.1:11434\")\n",
    "    try:\n",
    "        with urllib.request.urlopen(f\"{host}/api/tags\", timeout=3) as r:\n",
    "            json.load(r)  # ok\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Ollama not reachable at {host}. Start it or set OLLAMA_HOST. Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be734a0f-801d-450d-9275-67919f7aa7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_with_ollama(resume_text: str, model: str = \"llama3.1:8b\") -> ResumeOut:\n",
    "    \"\"\"\n",
    "    Requires: pip install ollama; and the Ollama daemon running.\n",
    "    Example models: 'llama3.1:8b', 'phi3:mini', 'mistral:7b'.\n",
    "    \"\"\"\n",
    "    import ollama\n",
    "    ensure_ollama()\n",
    "    schema = {\"name\":\"\", \"email\":\"\", \"skills\":[]}\n",
    "    user = (\n",
    "        \"Extract name, primary email, and skills. \"\n",
    "        \"Return JSON with keys exactly: name, email, skills.\\n\"\n",
    "        f\"Schema example:\\n{json.dumps(schema, indent=2)}\\n\\n\"\n",
    "        f\"{USER_TEMPLATE.format(chunk=truncate(resume_text))}\"\n",
    "    )\n",
    "    resp = ollama.chat(\n",
    "        model=model,\n",
    "        format=\"json\",\n",
    "        messages=[\n",
    "            {\"role\":\"system\", \"content\": SYSTEM_INSTRUCTIONS},\n",
    "            {\"role\":\"user\", \"content\": user},\n",
    "        ],\n",
    "        options={\"temperature\": 0, \"num_ctx\": 2048, \"num_predict\": 256}\n",
    "    )\n",
    "    data = repair_or_fill(resp[\"message\"][\"content\"])\n",
    "    return postprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c681d-5f0d-43d3-9f9e-cae756a3d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Orchestrator (free only) =====\n",
    "def parse_resume_llm(path: Path, model: str = \"llama3.1:8b\") -> ResumeOut:\n",
    "    text = read_text(path)\n",
    "    return parse_with_ollama(text, model=model)\n",
    "\n",
    "# ===== Batch =====\n",
    "def batch_folder(folder: Path, model: str = \"llama3.1:8b\") -> List[ResumeOut]:\n",
    "    outs=[]\n",
    "    for p in sorted(folder.iterdir()):\n",
    "        if p.suffix.lower() not in {\".pdf\",\".docx\"}: continue\n",
    "        try:\n",
    "            outs.append(parse_resume_llm(p, model=model))\n",
    "        except Exception as e:\n",
    "            outs.append(ResumeOut(name=\"\", email=\"\", skills=[f\"ERROR: {e}\"]))  # visible in UI\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554c323-f521-464d-ba48-b352d9cf2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse, json\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--resumes\", required=True, help=\"Folder with PDF/DOCX\")\n",
    "    ap.add_argument(\"--model\", default=\"llama3.1:8b\", help=\"Ollama model tag\")\n",
    "    ap.add_argument(\"--dump_json\", default=\"preds.jsonl\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    folder = Path(args.resumes)\n",
    "    with open(args.dump_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p in sorted(folder.iterdir()):\n",
    "            if p.suffix.lower() not in {\".pdf\",\".docx\"}:\n",
    "                continue\n",
    "            rec = parse_resume_llm(p, model=args.model.strip())\n",
    "            row = rec.model_dump()\n",
    "            row[\"file\"] = p.name\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ea41b-ac54-455c-8b76-a53e401df95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d9471-ce8a-4e9d-8b1c-9ae4a6c1fe2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97dc74-042c-4bd4-bc95-b8d75154275a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14a198-3f6d-491d-af62-893a1f698991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-env)",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
